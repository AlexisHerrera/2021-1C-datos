{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inf_retriev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos_contenido = {\"1\": \"saca casa\",\"2\": \"aca hay asas\", \"3\": \"casa asa saca\",\"4\": \"aca aca asta\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de terminos de los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* saca->1\n",
      "* casa->1\n",
      "* aca->2\n",
      "* hay->2\n",
      "* asas->2\n",
      "* casa->3\n",
      "* asa->3\n",
      "* saca->3\n",
      "* aca->4\n",
      "* aca->4\n",
      "* asta->4\n"
     ]
    }
   ],
   "source": [
    "palabras_documentos = {}\n",
    "for numero_doc,palabras in documentos_contenido.items():\n",
    "    palabras_lista = palabras.split(\" \")\n",
    "    for termino in palabras_lista:\n",
    "        print(f\"* {termino}->{numero_doc}\")\n",
    "        if termino in palabras_documentos and numero_doc in palabras_documentos[termino]:\n",
    "            continue\n",
    "        palabras_documentos[termino] = palabras_documentos.get(termino,\"\") + numero_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordeno el archivo por terminos y documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* aca->2\n",
      "* aca->4\n",
      "* asa->3\n",
      "* asas->2\n",
      "* asta->4\n",
      "* casa->1\n",
      "* casa->3\n",
      "* hay->2\n",
      "* saca->1\n",
      "* saca->3\n"
     ]
    }
   ],
   "source": [
    "palabras_documentos = dict(sorted(palabras_documentos.items()))\n",
    "for termino_ordenado,documento in palabras_documentos.items():\n",
    "    for numero_doc in documento:\n",
    "        print(f\"* {termino_ordenado}->{numero_doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unifico los terminos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* aca->2,4\n",
      "* asa->3\n",
      "* asas->2\n",
      "* asta->4\n",
      "* casa->1,3\n",
      "* hay->2\n",
      "* saca->1,3\n"
     ]
    }
   ],
   "source": [
    "for termino_ordenado,documento in palabras_documentos.items():\n",
    "    print(f\"* {termino_ordenado}->{','.join(list(documento))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codifico los archivos a distancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* aca->2,2\n",
      "* asa->3\n",
      "* asas->2\n",
      "* asta->4\n",
      "* casa->1,2\n",
      "* hay->2\n",
      "* saca->1,2\n"
     ]
    }
   ],
   "source": [
    "for termino_ordenado,documento in palabras_documentos.items():\n",
    "    print(f\"* {termino_ordenado}->{','.join(list(distancias_documentos(documento)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armado del léxico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| aca | asa | asas | asta | casa | hay | saca |\n",
      "| --- | --- | ---- | ---- | ---- | --- | ---- |\n",
      "| 0 | 3 | 6 | 10 | 14 | 18 | 21 |"
     ]
    }
   ],
   "source": [
    "terminos = palabras_documentos.keys()\n",
    "indice_lexico = crear_lexico(terminos)\n",
    "print_indice_markdown(indice_lexico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armado de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 6, 9, 12, 17, 21, 24], ['010010', '011', '010', '00100', '1010', '010', '1010'])\n",
      "| 010010 | 011 | 010 | 00100 | 1010 | 010 | 1010 |\n",
      "| ------ | --- | --- | ----- | ---- | --- | ---- |\n",
      "| 0 | 6 | 9 | 12 | 17 | 21 | 24 |"
     ]
    }
   ],
   "source": [
    "documentos = palabras_documentos.values()\n",
    "indice_documentos = crear_indice_documentos(documentos,modo='d',codificacion='g')\n",
    "print(indice_documentos)\n",
    "print_markdown_documentos(indice_documentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unificado indice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| punteros terminos | punteros documentos |\n",
      "| -------- | -------- |\n",
      "| 0 | 0 |\n",
      "| 3 | 6 |\n",
      "| 6 | 9 |\n",
      "| 10 | 12 |\n",
      "| 14 | 17 |\n",
      "| 18 | 21 |\n",
      "| 21 | 24 |\n",
      "\n",
      "| aca | asa | asas | asta | casa | hay | saca |\n",
      "| --- | --- | ---- | ---- | ---- | --- | ---- |\n",
      "| 0 | 3 | 6 | 10 | 14 | 18 | 21 |\n",
      "\n",
      "| 010010 | 011 | 010 | 00100 | 1010 | 010 | 1010 |\n",
      "| ------ | --- | --- | ----- | ---- | --- | ---- |\n",
      "| 0 | 6 | 9 | 12 | 17 | 21 | 24 |"
     ]
    }
   ],
   "source": [
    "print_markdown_indice_invertido(indice_lexico,indice_documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| posicion | punteros terminos | punteros documentos |\n",
      "| -------- | -------- | -------- |\n",
      "| 0|0 | 0 |\n",
      "| 1|3 | 6 |\n",
      "| 2|6 | 9 |\n",
      "| 3|10 | 12 |\n",
      "| 4|14 | 17 |\n",
      "| 5|18 | 21 |\n",
      "| 6|21 | 24 |\n",
      "\n",
      "| aca | asa | asas | asta | casa | hay | saca |\n",
      "| --- | --- | ---- | ---- | ---- | --- | ---- |\n",
      "| 0 | 3 | 6 | 10 | 14 | 18 | 21 |\n",
      "\n",
      "| 010010 | 011 | 010 | 00100 | 1010 | 010 | 1010 |\n",
      "| ------ | --- | --- | ----- | ---- | --- | ---- |\n",
      "| 0 | 6 | 9 | 12 | 17 | 21 | 24 |"
     ]
    }
   ],
   "source": [
    "print_markdown_indice_invertido_indexado(indice_lexico,indice_documentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicacion de TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos_contenido2 = {\"1\":\"aquel arbusto azul\",\"2\":\"amarillento arbol\",\"3\":\"amarillo arbusto azul\",\"4\":\"amarillento ancestral azul\"}\n",
    "documentos_contenido2 = {\"1\":\"la casa rosa\",\"2\":\"la rosa roja muy roja bien roja\",\"3\":\"la casa es roja\"}\n",
    "documentos_contenido2 = {\"1\":\"auto rojo\",\"2\":\"paisaje verde\",\"3\":\"muro naranja\",\"4\":\"rojo\",\"5\":\"amarillo verde rojo azul blanco naranja turquesa rojo\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* auto->1\n",
      "* rojo->1\n",
      "* paisaje->2\n",
      "* verde->2\n",
      "* muro->3\n",
      "* naranja->3\n",
      "* rojo->4\n",
      "* amarillo->5\n",
      "* verde->5\n",
      "* rojo->5\n",
      "* azul->5\n",
      "* blanco->5\n",
      "* naranja->5\n",
      "* turquesa->5\n",
      "* rojo->5\n"
     ]
    }
   ],
   "source": [
    "palabras_documentos = {}\n",
    "for numero_doc,palabras in documentos_contenido2.items():\n",
    "    palabras_lista = palabras.split(\" \")\n",
    "    for termino in palabras_lista:\n",
    "        print(f\"* {termino}->{numero_doc}\")\n",
    "        if termino in palabras_documentos and numero_doc in palabras_documentos[termino]:\n",
    "            continue\n",
    "        palabras_documentos[termino] = palabras_documentos.get(termino,\"\") + numero_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auto': '1',\n",
       " 'rojo': '145',\n",
       " 'paisaje': '2',\n",
       " 'verde': '25',\n",
       " 'muro': '3',\n",
       " 'naranja': '35',\n",
       " 'amarillo': '5',\n",
       " 'azul': '5',\n",
       " 'blanco': '5',\n",
       " 'turquesa': '5'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| terminos | 1 | 2 | 3 | 4 | 5 |  Log((N+1)/fti)|\n",
      "| --- | --- | --- | --- | --- | --- | --- |\n",
      "| auto | 1 | 0 | 0 | 0 | 0 |Log(6/1):0.78 |\n",
      "| rojo | 1 | 0 | 0 | 1 | 2 |Log(6/3):0.3 |\n",
      "| paisaje | 0 | 1 | 0 | 0 | 0 |Log(6/1):0.78 |\n",
      "| verde | 0 | 1 | 0 | 0 | 1 |Log(6/2):0.48 |\n",
      "| muro | 0 | 0 | 1 | 0 | 0 |Log(6/1):0.78 |\n",
      "| naranja | 0 | 0 | 1 | 0 | 1 |Log(6/2):0.48 |\n",
      "| amarillo | 0 | 0 | 0 | 0 | 1 |Log(6/1):0.78 |\n",
      "| azul | 0 | 0 | 0 | 0 | 1 |Log(6/1):0.78 |\n",
      "| blanco | 0 | 0 | 0 | 0 | 1 |Log(6/1):0.78 |\n",
      "| turquesa | 0 | 0 | 0 | 0 | 1 |Log(6/1):0.78 |\n"
     ]
    }
   ],
   "source": [
    "print_markdown_tabla_tf_idf(palabras_documentos,documentos_contenido2,modo=\"tf-idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| terminos | 1 | 2 | 3 | 4 | 5 |  Log((N+1)/fti)|\n",
      "| --- | --- | --- | --- | --- | --- | --- |\n",
      "| auto | 1.2 | 0.0 | 0.0 | 0.0 | 0.0 |Log(6/1):0.78 |\n",
      "| rojo | 1.2 | 0.0 | 0.0 | 1.5 | 0.92 |Log(6/3):0.3 |\n",
      "| paisaje | 0.0 | 1.2 | 0.0 | 0.0 | 0.0 |Log(6/1):0.78 |\n",
      "| verde | 0.0 | 1.2 | 0.0 | 0.0 | 0.55 |Log(6/2):0.48 |\n",
      "| muro | 0.0 | 0.0 | 1.2 | 0.0 | 0.0 |Log(6/1):0.78 |\n",
      "| naranja | 0.0 | 0.0 | 1.2 | 0.0 | 0.55 |Log(6/2):0.48 |\n",
      "| amarillo | 0.0 | 0.0 | 0.0 | 0.0 | 0.55 |Log(6/1):0.78 |\n",
      "| azul | 0.0 | 0.0 | 0.0 | 0.0 | 0.55 |Log(6/1):0.78 |\n",
      "| blanco | 0.0 | 0.0 | 0.0 | 0.0 | 0.55 |Log(6/1):0.78 |\n",
      "| turquesa | 0.0 | 0.0 | 0.0 | 0.0 | 0.55 |Log(6/1):0.78 |\n"
     ]
    }
   ],
   "source": [
    "print_markdown_tabla_tf_idf(palabras_documentos,documentos_contenido2,modo=\"bm25\",k=2,b=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| terminos | 1 | 2 | 3 | 4 | 5 |  Log((N+1)/fti)|\n",
      "| --- | --- | --- | --- | --- | --- | --- |\n",
      "| auto | 1.33 | 0.0 | 0.0 | 0.0 | 0.0 |Log(6/1):0.78 |\n",
      "| rojo | 1.33 | 0.0 | 0.0 | 2.0 | 0.89 |Log(6/3):0.3 |\n",
      "| paisaje | 0.0 | 1.33 | 0.0 | 0.0 | 0.0 |Log(6/1):0.78 |\n",
      "| verde | 0.0 | 1.33 | 0.0 | 0.0 | 0.44 |Log(6/2):0.48 |\n",
      "| muro | 0.0 | 0.0 | 1.33 | 0.0 | 0.0 |Log(6/1):0.78 |\n",
      "| naranja | 0.0 | 0.0 | 1.33 | 0.0 | 0.44 |Log(6/2):0.48 |\n",
      "| amarillo | 0.0 | 0.0 | 0.0 | 0.0 | 0.44 |Log(6/1):0.78 |\n",
      "| azul | 0.0 | 0.0 | 0.0 | 0.0 | 0.44 |Log(6/1):0.78 |\n",
      "| blanco | 0.0 | 0.0 | 0.0 | 0.0 | 0.44 |Log(6/1):0.78 |\n",
      "| turquesa | 0.0 | 0.0 | 0.0 | 0.0 | 0.44 |Log(6/1):0.78 |\n"
     ]
    }
   ],
   "source": [
    "print_markdown_tabla_tf_idf(palabras_documentos,documentos_contenido2,modo=\"tf-idf\",b=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| terminos | 1 | 2 | 3 | 4 | 5 |  Log((N+1)/fti)|\n",
      "| --- | --- | --- | --- | --- | --- | --- |\n",
      "| auto | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 |Log(6/1):0.78 |\n",
      "| rojo | 1.0 | 0.0 | 0.0 | 1.0 | 1.5 |Log(6/3):0.3 |\n",
      "| paisaje | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 |Log(6/1):0.78 |\n",
      "| verde | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 |Log(6/2):0.48 |\n",
      "| muro | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 |Log(6/1):0.78 |\n",
      "| naranja | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 |Log(6/2):0.48 |\n",
      "| amarillo | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 |Log(6/1):0.78 |\n",
      "| azul | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 |Log(6/1):0.78 |\n",
      "| blanco | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 |Log(6/1):0.78 |\n",
      "| turquesa | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 |Log(6/1):0.78 |\n"
     ]
    }
   ],
   "source": [
    "print_markdown_tabla_tf_idf(palabras_documentos,documentos_contenido2,modo=\"bm25\",k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
